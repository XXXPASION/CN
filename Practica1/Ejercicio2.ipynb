{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 2 Aproximaci칩n de funciones:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**1. 쮻ado un conjunto de n puntos, existe siempre un polinomio de grado m < n-1 que\n",
    "pase por dichos puntos?**\n",
    "\n",
    "\n",
    " S칤, dados N+1 puntos x0, x1, ..., xN pertenecientes al intervalo [a,b], existe siempre un polinomio llamado  polinomio de\n",
    "interpolacion de grado menor o igual que N que pasa por esos puntos que existe y adem치s es 칰nico. Es f치cilmente demostrable por  el determinante de Vandermonde.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**2. 쯉e te ocurre una manera en la cual el c치lculo de los valores singulares de una matriz\n",
    "permita calcular un polinomio de regresi칩n adecuado?**\n",
    "\n",
    "S칤. Tal y como comentamos en el ejercicio 3, podemos transformar el c치lculo del polinomio de regresi칩n en un problema de producto de matrices.\n",
    "\n",
    "\n",
    "Una matriz la podemos descomponer de la siguiente forma:\n",
    "                                    A = U*S*V_traspuesta\n",
    "                                    \n",
    "                                    donde \n",
    "                                        A: es LA matriz mxn\n",
    "                                        U: es una matriz unitaria mxm\n",
    "                                        V: es una matriz unitaria nxn\n",
    "                                        S: es una matriz diagonal con los valores singulares en la diagonal\n",
    " \n",
    "\n",
    "**3. 쮺omo podr칤as transformar el problema de encontrar un polinomio de regresi칩n en un\n",
    "problema de producto de matrices?**\n",
    "\n",
    "Dado que en regresi칩n lineal queremos encontrar un recta  que se ajuste lo mejor posible a los puntos dados, establecemos un conjunto de ecuaciones para cada punto de la forma:\n",
    "                                            y = 洧녫1洧논 + 洧녫2\n",
    " Dado que tenemos N puntos, tenemos un sistema de ecuaciones tal que:\n",
    "                                             y_i= 洧녫1_i洧논 + 洧녫2_i\n",
    "\n",
    " Que podemos expresar como una matriz de la forma:\n",
    "                                             洧냢 洧녫 = y\n",
    "                                           donde A = [X1 1\n",
    "                                           \n",
    "                                                      ...\n",
    "                                                      \n",
    "                                                      Xn 1]\n",
    "                                                      \n",
    "                                            , c = [c1 c2]\n",
    "                                            e y = [y1\n",
    "                                            \n",
    "                                                    ...\n",
    "                                                    \n",
    "                                                    yn]\n",
    " Obteniendo un sistema sobredeterminado. Por eso deseamos encontrar una recta que minimice las desviaciones a cada punto(error), tal que:\n",
    "                                     e_i = y_real - y_estimado\n",
    "                                     \n",
    "                                     siendo: y_estimado la ecuacion matricial anterior.\n",
    "  \n",
    "                                     \n",
    " Optimizando dicho error con la norma 2 de e, obtenemos que la soluci칩n es:\n",
    " \n",
    "                                             (A_traspuesa*A)*c = A_trapuesta*y\n",
    "             \n",
    " Es decir, hemos conseguido **transformar el problema de encontrar un polinomio de regresi칩n en un\n",
    "problema de producto de matrices**                                  \n",
    "             \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**4. 쮺rees que, adem치s, es posible calcular el error de regresi칩n a partir de los valores\n",
    "singulares?**\n",
    "\n",
    "\n",
    "**En general, los m칠todos de regresi칩n polin칩mica que hemos visto consisten en el c치lculo\n",
    "anal칤tico del m칤nimo de una funci칩n de error. Dicho calculo pasaba por calcular el gradiente de\n",
    "cierta funci칩n en igualarlo a 0. En esta pr치ctica vamos a ver que todos esos pasos no son\n",
    "realmente necesarios.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2\n",
    "\n",
    "# Data\n",
    "data = np.array([[1, 0 ,1], [2, 0.25, 1.2840], [3, 0.5, 1.6487], [2, 0.75, 2.1170], [2, 1, 2.7183]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
