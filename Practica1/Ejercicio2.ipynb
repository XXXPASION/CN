{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 2 Aproximación de funciones:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**1. ¿Dado un conjunto de n puntos, existe siempre un polinomio de grado m < n-1 que\n",
    "pase por dichos puntos?**\n",
    "\n",
    "\n",
    " Sí, dados N+1 puntos x0, x1, ..., xN pertenecientes al intervalo [a,b], existe siempre un polinomio llamado  polinomio de\n",
    "interpolacion de grado menor o igual que N que pasa por esos puntos que existe y además es único. Es fácilmente demostrable por  el determinante de Vandermonde.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**2. ¿Se te ocurre una manera en la cual el cálculo de los valores singulares de una matriz\n",
    "permita calcular un polinomio de regresión adecuado?**\n",
    "\n",
    "Sí. Tal y como comentamos en el ejercicio 3, podemos transformar el cálculo del polinomio de regresión en un problema de producto de matrices.\n",
    "\n",
    "\n",
    "Una matriz la podemos descomponer de la siguiente forma:\n",
    "                                    A = U*S*V_traspuesta\n",
    "                                    \n",
    "                                    donde \n",
    "                                        A: es LA matriz mxn\n",
    "                                        U: es una matriz unitaria mxm\n",
    "                                        V: es una matriz unitaria nxn\n",
    "                                        S: es una matriz diagonal con los valores singulares en la diagonal\n",
    " \n",
    "\n",
    "**3. ¿Como podrías transformar el problema de encontrar un polinomio de regresión en un\n",
    "problema de producto de matrices?**\n",
    "\n",
    "Dado que en regresión lineal queremos encontrar un recta  que se ajuste lo mejor posible a los puntos dados, establecemos un conjunto de ecuaciones para cada punto de la forma:\n",
    "                                            y = 𝑐1𝑥 + 𝑐2\n",
    " Dado que tenemos N puntos, tenemos un sistema de ecuaciones tal que:\n",
    "                                             y_i= 𝑐1_i𝑥 + 𝑐2_i\n",
    "\n",
    " Que podemos expresar como una matriz de la forma:\n",
    "                                             𝐴 𝑐 = y\n",
    "                                           donde A = [X1 1\n",
    "                                           \n",
    "                                                      ...\n",
    "                                                      \n",
    "                                                      Xn 1]\n",
    "                                                      \n",
    "                                            , c = [c1 c2]\n",
    "                                            e y = [y1\n",
    "                                            \n",
    "                                                    ...\n",
    "                                                    \n",
    "                                                    yn]\n",
    " Obteniendo un sistema sobredeterminado. Por eso deseamos encontrar una recta que minimice las desviaciones a cada punto(error), tal que:\n",
    "                                     e_i = y_real - y_estimado\n",
    "                                     \n",
    "                                     siendo: y_estimado la ecuacion matricial anterior.\n",
    "  \n",
    "                                     \n",
    " Optimizando dicho error con la norma 2 de e, obtenemos que la solución es:\n",
    " \n",
    "                                             (A_traspuesa*A)*c = A_trapuesta*y\n",
    "             \n",
    " Es decir, hemos conseguido **transformar el problema de encontrar un polinomio de regresión en un\n",
    "problema de producto de matrices**                                  \n",
    "             \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**4. ¿Crees que, además, es posible calcular el error de regresión a partir de los valores\n",
    "singulares?**\n",
    "\n",
    "\n",
    "**En general, los métodos de regresión polinómica que hemos visto consisten en el cálculo\n",
    "analítico del mínimo de una función de error. Dicho calculo pasaba por calcular el gradiente de\n",
    "cierta función en igualarlo a 0. En esta práctica vamos a ver que todos esos pasos no son\n",
    "realmente necesarios.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2\n",
    "\n",
    "# Data\n",
    "data = np.array([[1, 0 ,1], [2, 0.25, 1.2840], [3, 0.5, 1.6487], [2, 0.75, 2.1170], [2, 1, 2.7183]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
